# Project Title
This project was conducted during the Deeplearning Programming class in the first semester of 2024.
<br><br>

# Project Background 
Marine debris threatens our living environment and ecosystems, emerging as a global environmental issue. It causes ecosystem destruction and economic losses, negatively impacting tourism and fisheries. Detecting marine debris in vast ocean areas and deep-sea environments is a challenging task. To overcome this, technology that can effectively detect and manage marine debris is needed.<br><br>
This study uses deep learning technology with an object detection model to accurately identify the location and distribution of marine debris. Estimating the size of debris through segmentation requires data labeling, which incurs significant costs. By using YOLO and SAM to effectively detect marine debris and obtain pseudo segmentation labels, we can reduce data construction costs and contribute to weakly supervised learning. Ultimately, providing higher quality labels can foster deeper research in this field.
<br><br>

# Project Process  

## Stack
### Language & Library
<div>
  <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white"/>

  <img src="https://img.shields.io/badge/Pytorch-EE4C2C?style=flat&logo=Pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/Numpy-013243?style=flat&logo=Numpy&logoColor=white"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=flat&logo=Pandas&logoColor=white"/>
  <img src="https://img.shields.io/badge/wandb-ECD53F?style=flat&&logoColor=white"/>
</div>

### Model
<div>
  <img src="https://img.shields.io/badge/YOLOv8-000000?style=flat&logo=&logoColor=white"/>
  <img src="https://img.shields.io/badge/SAM-000000?style=flat&logo=&logoColor=white"/>
  <img src="https://img.shields.io/badge/Sea_thru-000000?style=flat&logo=&logoColor=white"/>
</div>
<br><br>

## Pipeline
### Dataset
We used marine debris images from the disaster safety data provided by [**AI-Hub.**](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=236)   
This dataset consists of approximately 46,000 sonar survey images and about 18,000 underwater photography images. For this study, we only used the underwater photography images.

### Preprocessing
- Out of the 18,000 images, we removed those with multiple objects or no objects, resulting in approximately 12,000 images. 
- For training, we set the ratio of train, validation, and test sets to 7:1:2. 
- Since YOLOv8 automatically performs augmentation, we only used ImageNet normalization and resizing for preprocessing, without any additional augmentation.
<br><br>

### Modeling

In this study, we used two models: YOLOv8n for the training model and SAM for pseudo labeling. For YOLOv8n, we used the model provided by Ultralytics, which was pre-trained on the COCO dataset and then fine-tuned on our dataset. We used AdamW (lr=0.001111, momentum=0.9) as the optimizer, set the batch size to 128, and ran a total of 50 epochs. For SAM, we used a pre-trained ViT-H as the backbone and performed segmentation using prompts from the bounding boxes generated by YOLO.
![image](https://github.com/YunSeoHwan/DL_Programming/assets/48356954/fbafe018-dc23-4570-b5ac-2f9b155cd048)

### Role
#### [**YunSeoHwan**](https://github.com/YunSeoHwan) : Research, Preprocessing, Modeling, Interpretation<br>
#### KimSangSu: Research, Data Loading, Preprocessing
#### KimJiHoon : Research, Preprocessing
#### SongInSeop : Research, Preprocessing <br>
<br><br>
# Result & Suggestion
## Experimental Results
The metrics for this experiment include precision, recall, and F1 score for class predictions, as well as mAP50 and mAP50-95 for bounding boxes. As shown in the table below, the results of YOLOv8s are higher in the test set compared to the train set, indicating that the model is not overfitting and demonstrates generalized performance. Additionally, it shows better performance than the AI-Hub benchmark score of mAP50 0.75.
![image](https://github.com/YunSeoHwan/BD_Recommendation_System/assets/48356954/948b2be5-0d2c-4e6e-a985-360f8d241c3f)
<br><Br><br>


![image](https://github.com/YunSeoHwan/BD_Recommendation_System/assets/48356954/424b8f21-52ed-47b1-93e3-0cdaf45f721d)
![image](https://github.com/YunSeoHwan/BD_Recommendation_System/assets/48356954/0f5ca953-9ff3-4e63-bda0-ff1f1c2f28f6)

For SAM, we used bounding boxes generated from Ground Truth and YOLO predictions as prompts for segmentation. Figure 1 shows good segmentation results from both Ground Truth and YOLO. However, in Figure 2, the Ground Truth segmentation was less accurate than the YOLO-based segmentation. This indicates that our YOLO model provides more robust bounding boxes compared to the Ground Truth, which in turn allows SAM to deliver robust performance. Additionally, the average inference time for SAM is 0.05 seconds, reducing the manual task time, which usually takes tens of minutes, by approximately 10,000 times. Therefore, this study not only achieves effective marine debris detection but also significantly reduces the cost and time for generating pseudo labels by several thousand times.

